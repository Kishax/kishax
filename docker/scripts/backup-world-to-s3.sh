#!/bin/bash
# ================================================================
# S3 World Backup Script
# ================================================================
# Backup Minecraft world data to S3 bucket on demand
#
# Usage: ./backup-world-to-s3.sh [OPTIONS]
# Location: EC2 i-a instance, inside Docker container (/mc/scripts/)
# Returns: 0=success, 1=error
# ================================================================

set -e

# ================================================================
# Configuration
# ================================================================

CONFIG_FILE="/mc/config/servers.json"
S3_BUCKET="${S3_BUCKET:-kishax-production-world-backups}"
S3_BACKUP_PREFIX="${S3_BACKUP_PREFIX:-backups/}"
AWS_REGION="${AWS_REGION:-ap-northeast-1}"
BACKUP_DIR="/tmp/mc-backup-$$"
DATE=$(date +%Y%m%d)
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
COMPRESSION_LEVEL=6
DRY_RUN=false
TARGET_SERVER=""

# Color output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ================================================================
# Helper Functions
# ================================================================

print_header() {
    echo -e "${BLUE}=== $1 ===${NC}"
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

# ================================================================
# Options Parser
# ================================================================

usage() {
    cat << EOF
S3 World Backup Script

Usage: $0 [OPTIONS]

Options:
  --dry-run                ÂÆüÈöõ„Å´„ÅØ„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åõ„Åö„ÄÅ‰Ωï„ÅåÂÆüË°å„Åï„Çå„Çã„ÅãÁ¢∫Ë™ç
  --server <name>          ÁâπÂÆö„Çµ„Éº„Éê„Éº„ÅÆ„Åø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
  --compression <1-9>      ÂúßÁ∏Æ„É¨„Éô„É´ (1=ÈÄü„ÅÑ/Â§ß„Åç„ÅÑ, 9=ÈÅÖ„ÅÑ/Â∞è„Åï„ÅÑ, „Éá„Éï„Ç©„É´„Éà: 6)
  --help                   „Åì„ÅÆ„Éò„É´„Éó„ÇíË°®Á§∫

Examples:
  $0                                    # ÂÖ®„Çµ„Éº„Éê„Éº„Çí„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
  $0 --dry-run                          # „Éâ„É©„Ç§„É©„É≥
  $0 --server home                      # home„Çµ„Éº„Éê„Éº„ÅÆ„Åø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
  $0 --compression 9 --server latest    # latest„Çµ„Éº„Éê„Éº„ÇíÊúÄÂ§ßÂúßÁ∏Æ„Åß„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó

Environment Variables:
  S3_BUCKET            S3„Éê„Ç±„ÉÉ„ÉàÂêç („Éá„Éï„Ç©„É´„Éà: kishax-production-world-backups)
  S3_BACKUP_PREFIX     S3„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ („Éá„Éï„Ç©„É´„Éà: backups/)
  AWS_REGION           AWS„É™„Éº„Ç∏„Éß„É≥ („Éá„Éï„Ç©„É´„Éà: ap-northeast-1)
EOF
    exit 0
}

while [[ $# -gt 0 ]]; do
    case $1 in
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --server)
            TARGET_SERVER="$2"
            shift 2
            ;;
        --compression)
            COMPRESSION_LEVEL="$2"
            if [[ ! "$COMPRESSION_LEVEL" =~ ^[1-9]$ ]]; then
                print_error "ÂúßÁ∏Æ„É¨„Éô„É´„ÅØ1-9„ÅÆÊï∞ÂÄ§„ÅßÊåáÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
                exit 1
            fi
            shift 2
            ;;
        --help)
            usage
            ;;
        *)
            print_error "‰∏çÊòé„Å™„Ç™„Éó„Ç∑„Éß„É≥: $1"
            echo "„Éò„É´„Éó„ÇíË°®Á§∫: $0 --help"
            exit 1
            ;;
    esac
done

# ================================================================
# Prerequisites Check
# ================================================================

check_prerequisites() {
    print_header "ÂâçÊèêÊù°‰ª∂„ÉÅ„Çß„ÉÉ„ÇØ"

    # servers.json existence
    if [ ! -f "$CONFIG_FILE" ]; then
        print_error "Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: $CONFIG_FILE"
        exit 1
    fi
    print_success "Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Á¢∫Ë™ç: $CONFIG_FILE"

    # jq command
    if ! command -v jq &> /dev/null; then
        print_error "jq „Ç≥„Éû„É≥„Éâ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì"
        exit 1
    fi
    print_success "jq „Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„Åø"

    # AWS CLI
    if ! command -v aws &> /dev/null; then
        print_error "AWS CLI „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì"
        exit 1
    fi
    print_success "AWS CLI „Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„Åø"

    # S3 bucket access check
    if [ "$DRY_RUN" = false ]; then
        if ! aws s3 ls "s3://$S3_BUCKET" --region "$AWS_REGION" &> /dev/null; then
            print_error "S3„Éê„Ç±„ÉÉ„Éà„Å´„Ç¢„ÇØ„Çª„Çπ„Åß„Åç„Åæ„Åõ„Çì: s3://$S3_BUCKET"
            print_info "IAM„É≠„Éº„É´Ê®©Èôê„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
            exit 1
        fi
        print_success "S3„Éê„Ç±„ÉÉ„Éà„Ç¢„ÇØ„Çª„ÇπÁ¢∫Ë™ç"
    else
        print_info "„Éâ„É©„Ç§„É©„É≥„É¢„Éº„Éâ: S3„Ç¢„ÇØ„Çª„Çπ„ÉÅ„Çß„ÉÉ„ÇØ„Çí„Çπ„Ç≠„ÉÉ„Éó"
    fi

    echo ""
}

# ================================================================
# Get Active Servers
# ================================================================

get_active_servers() {
    local servers=()
    local spigot_count=$(jq -r '.spigots | length' "$CONFIG_FILE")

    for ((i=0; i<spigot_count; i++)); do
        local name=$(jq -r ".spigots[$i].name" "$CONFIG_FILE")
        local memory_ratio=$(jq -r ".spigots[$i].memory_ratio" "$CONFIG_FILE")

        # Skip disabled servers (memory_ratio = 0)
        if (( $(echo "$memory_ratio == 0" | bc -l) )); then
            continue
        fi

        # If target server specified, only include that server
        if [ -n "$TARGET_SERVER" ] && [ "$name" != "$TARGET_SERVER" ]; then
            continue
        fi

        servers+=("$name")
    done

    echo "${servers[@]}"
}

# ================================================================
# Backup Single Server
# ================================================================

backup_server() {
    local server_name=$1
    local server_dir="/mc/spigot/$server_name"
    local backup_server_dir="$BACKUP_DIR/$server_name"
    local s3_backup_path="$S3_BACKUP_PREFIX$DATE/$server_name"

    print_header "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó: $server_name"

    # Check if server directory exists
    if [ ! -d "$server_dir" ]; then
        print_warning "„Çµ„Éº„Éê„Éº„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: $server_dir"
        return 1
    fi

    # Create backup directory
    mkdir -p "$backup_server_dir"

    # Dynamically detect all world directories (world*)
    local world_types=()
    while IFS= read -r -d '' world_dir; do
        world_types+=("$(basename "$world_dir")")
    done < <(find "$server_dir" -maxdepth 1 -type d -name "world*" -print0 | sort -z)

    if [ ${#world_types[@]} -eq 0 ]; then
        print_warning "„ÉØ„Éº„É´„Éâ„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: $server_dir"
        return 1
    fi

    print_info "  Ê§úÂá∫„Åï„Çå„Åü„ÉØ„Éº„É´„Éâ: ${world_types[*]}"

    local backup_count=0
    local total_size=0

    for world_type in "${world_types[@]}"; do
        local world_path="$server_dir/$world_type"

        if [ ! -d "$world_path" ]; then
            print_info "  ‚è≠Ô∏è  $world_type: „Éá„Ç£„É¨„ÇØ„Éà„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„ÇìÔºà„Çπ„Ç≠„ÉÉ„ÉóÔºâ"
            continue
        fi

        print_info "  üì¶ $world_type: ÂúßÁ∏Æ‰∏≠..."

        # Calculate world size before compression
        local world_size=$(du -sh "$world_path" 2>/dev/null | cut -f1)
        print_info "     „Çµ„Ç§„Ç∫: $world_size"

        # Create tar.gz archive
        local archive_name="${world_type}.tar.gz"
        local archive_path="$backup_server_dir/$archive_name"

        if tar -cf "$archive_path" -C "$server_dir" "$world_type" --use-compress-program="gzip -$COMPRESSION_LEVEL" 2>/dev/null; then
            local archive_size=$(du -sh "$archive_path" | cut -f1)
            print_success "     ÂúßÁ∏ÆÂÆå‰∫Ü: $archive_size"
            backup_count=$((backup_count + 1))

            # Calculate total backup size
            local archive_bytes=$(du -sb "$archive_path" | cut -f1)
            total_size=$((total_size + archive_bytes))
        else
            print_error "     ÂúßÁ∏ÆÂ§±Êïó: $world_type"
            return 1
        fi
    done

    if [ $backup_count -eq 0 ]; then
        print_warning "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂØæË±°„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü: $server_name"
        return 1
    fi

    # Create metadata file
    print_info "  üìù „É°„Çø„Éá„Éº„Çø‰ΩúÊàê‰∏≠..."

    local metadata_file="$backup_server_dir/metadata.json"
    cat > "$metadata_file" << EOF
{
  "server": "$server_name",
  "backup_date": "$DATE",
  "timestamp": "$TIMESTAMP",
  "compression_level": $COMPRESSION_LEVEL,
  "total_size_bytes": $total_size,
  "worlds": [
EOF

    local first=true
    for world_type in "${world_types[@]}"; do
        local archive_path="$backup_server_dir/${world_type}.tar.gz"
        if [ -f "$archive_path" ]; then
            if [ "$first" = false ]; then
                echo "," >> "$metadata_file"
            fi
            first=false

            local size=$(du -sb "$archive_path" | cut -f1)
            cat >> "$metadata_file" << EOF
    {
      "world": "$world_type",
      "archive": "${world_type}.tar.gz",
      "size_bytes": $size
    }
EOF
        fi
    done

    cat >> "$metadata_file" << EOF

  ]
}
EOF

    print_success "  „É°„Çø„Éá„Éº„Çø‰ΩúÊàêÂÆå‰∫Ü"

    # Upload to S3
    if [ "$DRY_RUN" = false ]; then
        print_info "  üì§ S3„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ‰∏≠: s3://$S3_BUCKET/$s3_backup_path/"

        if aws s3 sync "$backup_server_dir/" "s3://$S3_BUCKET/$s3_backup_path/" \
            --region "$AWS_REGION" \
            --no-progress; then
            print_success "  S3„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂÆå‰∫Ü"
        else
            print_error "  S3„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂ§±Êïó"
            return 1
        fi

        # Create backup success flag
        echo "Backup completed at $TIMESTAMP" | \
            aws s3 cp - "s3://$S3_BUCKET/$s3_backup_path/__BACKUP_COMPLETED__" \
            --region "$AWS_REGION"

        print_success "  „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Éï„É©„Ç∞‰ΩúÊàêÂÆå‰∫Ü"
    else
        print_info "  (dryrun) S3„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Çí„Çπ„Ç≠„ÉÉ„Éó: s3://$S3_BUCKET/$s3_backup_path/"
    fi

    echo ""
    return 0
}

# ================================================================
# Cleanup
# ================================================================

cleanup() {
    if [ -d "$BACKUP_DIR" ]; then
        print_info "‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„Çí„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó‰∏≠..."
        rm -rf "$BACKUP_DIR"
        print_success "„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü"
    fi
}

# ================================================================
# Main
# ================================================================

main() {
    clear

    print_header "S3 World Backup Script"
    echo "üìÖ Êó•‰ªò: $DATE"
    echo "üìç S3„Éê„Ç±„ÉÉ„Éà: s3://$S3_BUCKET/$S3_BACKUP_PREFIX$DATE/"
    echo "üóúÔ∏è  ÂúßÁ∏Æ„É¨„Éô„É´: $COMPRESSION_LEVEL"
    echo "üîß AWS „É™„Éº„Ç∏„Éß„É≥: $AWS_REGION"

    if [ -n "$TARGET_SERVER" ]; then
        echo "üéØ ÂØæË±°„Çµ„Éº„Éê„Éº: $TARGET_SERVER"
    fi

    if [ "$DRY_RUN" = true ]; then
        print_warning "üß™ „Éâ„É©„Ç§„É©„É≥„É¢„Éº„ÉâÔºàÂÆüÈöõ„Å´„ÅØ„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Åæ„Åõ„ÇìÔºâ"
    fi

    echo ""

    # Prerequisites check
    check_prerequisites

    # Get active servers
    print_header "ÂØæË±°„Çµ„Éº„Éê„ÉºÂèñÂæó"
    local servers=($(get_active_servers))

    if [ ${#servers[@]} -eq 0 ]; then
        if [ -n "$TARGET_SERVER" ]; then
            print_error "ÊåáÂÆö„Åï„Çå„Åü„Çµ„Éº„Éê„Éº„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: $TARGET_SERVER"
        else
            print_error "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÂØæË±°„Çµ„Éº„Éê„Éº„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì"
        fi
        exit 1
    fi

    echo "üìã ÂØæË±°„Çµ„Éº„Éê„ÉºÊï∞: ${#servers[@]}"
    for server in "${servers[@]}"; do
        echo "  - $server"
    done
    echo ""

    # Confirmation
    if [ "$DRY_RUN" = false ]; then
        read -p "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÇíÈñãÂßã„Åó„Åæ„Åô„ÅãÔºü (y/N): " answer
        if [ "$answer" != "y" ] && [ "$answer" != "Y" ]; then
            print_info "„Ç≠„É£„É≥„Çª„É´„Åó„Åæ„Åó„Åü"
            exit 0
        fi
        echo ""
    fi

    # Create backup directory
    mkdir -p "$BACKUP_DIR"

    # Backup each server
    local success_count=0
    local fail_count=0

    for server in "${servers[@]}"; do
        if backup_server "$server"; then
            success_count=$((success_count + 1))
        else
            fail_count=$((fail_count + 1))
        fi
    done

    # Cleanup
    cleanup

    # Summary
    echo ""
    print_header "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„ÉóÁµêÊûú"
    echo "‚úÖ ÊàêÂäü: $success_count"
    echo "‚ùå Â§±Êïó: $fail_count"
    echo ""

    if [ "$DRY_RUN" = false ] && [ $success_count -gt 0 ]; then
        print_success "„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ"
        echo ""
        print_info "Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó:"
        print_info "1. S3„ÅÆÂÜÖÂÆπ„ÇíÁ¢∫Ë™ç:"
        print_info "   aws s3 ls s3://$S3_BUCKET/$S3_BACKUP_PREFIX$DATE/ --recursive --human-readable"
        print_info ""
        print_info "2. „Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Åã„ÇâÂæ©ÂÖÉ:"
        print_info "   make backup-world-restore DATE=$DATE"
    elif [ "$DRY_RUN" = true ]; then
        print_info "„Éâ„É©„Ç§„É©„É≥„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü"
        print_info "ÂÆüÈöõ„Å´„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„ÇíÂÆüË°å„Åô„Çã„Å´„ÅØ„ÄÅ--dry-run „Ç™„Éó„Ç∑„Éß„É≥„ÇíÂ§ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ"
    fi

    echo ""

    if [ $fail_count -gt 0 ]; then
        exit 1
    fi

    exit 0
}

# Trap cleanup on exit
trap cleanup EXIT

# Execute main
main
